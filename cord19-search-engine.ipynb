{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dwight\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path, PurePath\n",
    "from cord.core import parallel, ifnone\n",
    "import json\n",
    "import pprint\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/CORD-19-research-challenge/2020-03-13')\n",
    "biorxiv = data_path / 'biorxiv_medrxiv/biorxiv_medrxiv'\n",
    "comm_use = data_path / 'comm_use_subset/comm_use_subset'\n",
    "noncomm_use = data_path / 'noncomm_use_subset/noncomm_use_subset'\n",
    "pmc_custom_license = data_path / 'pmc_custom_license/pmc_custom_license'\n",
    "metadata_path = PurePath(data_path) / 'all_sources_metadata_2020-03-13.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/CORD-19-research-challenge/2020-03-13/all_sources_metadata_2020-03-13.csv'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/all_sources_metadata_2020-03-13.readme'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/biorxiv_medrxiv'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/comm_use_subset'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/COVID.DATA.LIC.AGMT.pdf'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/json_schema.txt'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/noncomm_use_subset'),\n",
       " WindowsPath('data/CORD-19-research-challenge/2020-03-13/pmc_custom_license')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_path.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading the JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author:\n",
    "    \n",
    "    def __init__(self, first=None, last=None, middle=None):\n",
    "        self.first = ifnone(first, '')\n",
    "        self.last = ifnone(last, '')\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.first} {self.last}'\n",
    "        \n",
    "class JPaper:\n",
    "    \n",
    "    def __init__(self, paper):\n",
    "        self.paper = paper\n",
    "        self.sha = paper['paper_id']\n",
    "        self.abstract = '\\n'.join([a['text'] for a in paper['abstract']])\n",
    "        self.title = paper['metadata']['title']\n",
    "        self.authors = [Author(a.get('first'), a.get('last'), a.get('middle') ) \n",
    "                              for a in paper['metadata']['authors']]\n",
    "        self.sections = [{s['section']: s['text']} for s in paper['body_text']]\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        _html = f'<h4>{self.title}</h4>'\n",
    "        return _html\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.title}'\n",
    "        \n",
    "        \n",
    "def load_json(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        contents = json.load(f)\n",
    "        jpaper = JPaper(contents)\n",
    "    return jpaper\n",
    "\n",
    "class JCatalog:\n",
    "    \n",
    "    def __init__(self, papers):\n",
    "        self.papers = papers\n",
    "        self.paper_index = {p.sha: p for p in self.papers}\n",
    "        self.index = pd.Series(self.papers, index=[p.sha for p in papers])\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, json_catalog_path):\n",
    "        print('Load JSON from', json_catalog_path)\n",
    "        papers = parallel(load_json, list(json_catalog_path.glob('*.json')))\n",
    "        return cls(papers)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if isinstance(item, int):\n",
    "            return self.papers[item]\n",
    "        return self.index.loc[item]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.papers)\n",
    "    \n",
    "    def __add__(self, o): \n",
    "        return JCatalog(self.papers + o.papers)  \n",
    "\n",
    "def add(cat1, cat2):\n",
    "    return cat1 + cat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = list(set(stopwords.words('english')))\n",
    "\n",
    "def tokenize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return list(set([word for word in words if word.isalnum() \n",
    "                                             and not word in english_stopwords\n",
    "                                             and not (word.isnumeric() and len(word) < 4)]))\n",
    "def preprocess(string):\n",
    "    return tokenize(string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the All Sources Metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the metadata from data\\CORD-19-research-challenge\\2020-03-13\\all_sources_metadata_2020-03-13.csv\n",
      "Load JSON from data\\CORD-19-research-challenge\\2020-03-13\\biorxiv_medrxiv\\biorxiv_medrxiv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc3159905874cf1a4e71372acf59d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=803.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load JSON from data\\CORD-19-research-challenge\\2020-03-13\\comm_use_subset\\comm_use_subset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8da89172e84484a9161bf3f6b959f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load JSON from data\\CORD-19-research-challenge\\2020-03-13\\noncomm_use_subset\\noncomm_use_subset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cad0847be941108173f91a710029cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load JSON from data\\CORD-19-research-challenge\\2020-03-13\\pmc_custom_license\\pmc_custom_license\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b82a7e565d4cbe8212eeb50783ed78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1426.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building a BM25 index\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import gc\n",
    "\n",
    "def get(url, timeout=6):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout)\n",
    "        return r.text\n",
    "    except ConnectionError:\n",
    "        print(f'Cannot connect to {url}')\n",
    "        print(f'Remember to turn Internet ON in the Kaggle notebook settings')\n",
    "    except HTTPError:\n",
    "        print('Got http error', r.status, r.text)\n",
    "    \n",
    "DISPLAY_COLS = ['sha','title','abstract','publish_time','authors','has_full_text']\n",
    "class ResearchPapers:\n",
    "    \n",
    "    def __init__(self, metadata, json_catalog):\n",
    "        self.metadata = metadata\n",
    "        self.json_catalog = json_catalog\n",
    "        print('Building a BM25 index')\n",
    "        index_tokens = self._create_index_tokens()\n",
    "        self.bm25 = BM25Okapi(index_tokens.tolist())\n",
    "        gc.collect()\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        if isinstance(item, int):\n",
    "            paper = self.metadata.iloc[item]\n",
    "        else:\n",
    "            paper = self.metadata[self.metadata.sha==item]\n",
    "        # Look up for the corresponding json paper if it exists\n",
    "        if isinstance(paper.sha, float) and np.isnan(paper.sha):\n",
    "            json_paper = None # No sha on the metadata row\n",
    "        else:\n",
    "            json_paper = self.json_catalog[paper.sha]\n",
    "        return Paper(paper, json_paper)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def head(self, n):\n",
    "        return ResearchPapers(self.metadata.head(n).copy().reset_index(drop=True))\n",
    "    \n",
    "    def tail(self, n):\n",
    "        return ResearchPapers(self.metadata.tail(n).copy().reset_index(drop=True))\n",
    "    \n",
    "    def abstracts(self):\n",
    "        return pd.Series([self.__getitem__(i).abstract() for i in range(len(self))])\n",
    "    \n",
    "    def titles(self):\n",
    "        return pd.Series([self.__getitem__(i).title() for i in range(len(self))])\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return self.metadata._repr_html_()\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, metadata_path, json_paths: List):\n",
    "        print('Loading the metadata from', metadata_path)\n",
    "        metadata = pd.read_csv(metadata_path, \n",
    "                              dtype={'Microsoft Academic Paper ID': str,\n",
    "                                     'pubmed_id': str})\n",
    "        # Convert the doi to a url\n",
    "        def doi_url(d): return f'http://{d}' if d.startswith('doi.org') else f'http://doi.org/{d}'\n",
    "        metadata.doi = metadata.doi.fillna('').apply(doi_url)\n",
    "\n",
    "        # Set the abstract to the paper title if it is null\n",
    "        metadata.abstract = metadata.abstract.fillna(metadata.title)\n",
    "        # Some papers are duplicated since they were collected from separate sources. Thanks Joerg Rings\n",
    "        duplicate_paper = ~(metadata.title.isnull() | metadata.abstract.isnull()) \\\n",
    "                & (metadata.duplicated(subset=['title', 'abstract']))\n",
    "        metadata = metadata[~duplicate_paper].reset_index(drop=True)\n",
    "        \n",
    "        catalogs = [JCatalog.load(p) for p in json_paths]\n",
    "        json_catalog = reduce(add, catalogs)\n",
    "        return cls(metadata, json_catalog)\n",
    "    \n",
    "    def _create_index_tokens(self):\n",
    "        abstracts = self.metadata[['sha', 'abstract']]\n",
    "        json_abstracts = self.json_catalog \\\n",
    "                                    .index.apply(lambda p: p.abstract) \\\n",
    "                                    .fillna('').to_frame(name='json_abstract') \\\n",
    "                                    .reset_index().rename(columns={'index': 'sha'})\n",
    "        abs_merged = abstracts.merge(json_abstracts, on='sha', how='left')\n",
    "        abstract_col = abs_merged.abstract + ' ' + abs_merged.json_abstract\n",
    "        abstract_col = abstract_col.fillna('')\n",
    "        abstract_tokens = abstract_col.str.lower().apply(tokenize)\n",
    "        return abstract_tokens\n",
    "        \n",
    "    def search(self, search_string, n=10):\n",
    "        search_terms = preprocess(search_string)\n",
    "        doc_scores = self.bm25.get_scores(search_terms)\n",
    "        ind = np.argsort(doc_scores)[::-1][:n]\n",
    "        results = self.metadata.iloc[ind].copy()\n",
    "        results['Score'] = doc_scores[ind]\n",
    "        results = results[results.Score > 0].copy()\n",
    "        return SearchResults(results)\n",
    "    \n",
    "class Paper:\n",
    "    \n",
    "    '''\n",
    "    A single research paper\n",
    "    '''\n",
    "    def __init__(self, item, json_paper):\n",
    "        self.sha = item.sha\n",
    "        self.paper = item.to_frame().fillna('')\n",
    "        self.paper.columns = ['Value']\n",
    "        self.json_paper = json_paper\n",
    "    \n",
    "    def doi(self):\n",
    "        return self.paper.loc['doi'].values[0]\n",
    "    \n",
    "    def html(self):\n",
    "        '''\n",
    "        Load the paper from doi.org and display as HTML. Requires internet to be ON\n",
    "        '''\n",
    "        text = get(self.doi())\n",
    "        return widgets.HTML(text)\n",
    "    \n",
    "    def text(self):\n",
    "        '''\n",
    "        Load the paper from doi.org and display as text. Requires Internet to be ON\n",
    "        '''\n",
    "        if self.json_paper:\n",
    "            return self.json_paper.text()\n",
    "        return get(self.doi())\n",
    "    \n",
    "    def abstract(self):\n",
    "        if self.json_paper:\n",
    "            abstract = self.json_paper.abstract\n",
    "            if abstract:\n",
    "                return abstract\n",
    "        return self.paper.loc['abstract'].values[0]\n",
    "    \n",
    "    def title(self):\n",
    "        if self.json_paper:\n",
    "            title = self.json_paper.title\n",
    "            if title:\n",
    "                return title\n",
    "        return self.paper.loc['title'].values[0]\n",
    "    \n",
    "    def authors(self, split=False):\n",
    "        if self.json_paper:\n",
    "            return self.json_paper.authors\n",
    "        '''\n",
    "        Get a list of authors\n",
    "        '''\n",
    "        authors = self.paper.loc['authors'].values[0]\n",
    "        if not authors:\n",
    "            return []\n",
    "        if not split:\n",
    "            return authors\n",
    "        if authors.startswith('['):\n",
    "            authors = authors.lstrip('[').rstrip(']')\n",
    "            return [a.strip().replace(\"\\'\", \"\") for a in authors.split(\"\\',\")]\n",
    "        \n",
    "        # Todo: Handle cases where author names are separated by \",\"\n",
    "        return [a.strip() for a in authors.split(';')]\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return self.paper._repr_html_()\n",
    "    \n",
    "class SearchResults:\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.results = data\n",
    "        self.columns = [col for col in ['sha','title','abstract','publish_time',\n",
    "                                        'authors', 'Score'] if col in data]\n",
    "            \n",
    "    def __getitem__(self, item):\n",
    "        return Paper(self.results.loc[item])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.results)\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        display_cols = [col for col in self.columns if not col == 'sha']\n",
    "        return self.results[display_cols]._repr_html_()\n",
    "    \n",
    "research_papers = ResearchPapers.load(metadata_path, \n",
    "                                  json_paths=[biorxiv, comm_use, noncomm_use, pmc_custom_license])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13110</th>\n",
       "      <td>Population-Level Effect of Cholera Vaccine on ...</td>\n",
       "      <td>Following mass population displacements in Sou...</td>\n",
       "      <td>2016 Jun</td>\n",
       "      <td>['Azman, Andrew S.', 'Rumunu, John', 'Abubakar...</td>\n",
       "      <td>7.078150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13291</th>\n",
       "      <td>Influence of Population Immunosuppression and ...</td>\n",
       "      <td>We built a SEIR (susceptible, exposed, infecte...</td>\n",
       "      <td>2018 Apr</td>\n",
       "      <td>['MacIntyre, C. Raina', 'Costantino, Valentina...</td>\n",
       "      <td>5.448692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>Monitoring and Characterization of Oseltamivir...</td>\n",
       "      <td>To monitor and characterize oseltamivir-resist...</td>\n",
       "      <td>2011 Mar</td>\n",
       "      <td>['Ujike, Makoto', 'Ejima, Miho', 'Anraku, Akan...</td>\n",
       "      <td>5.402628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>Blocking transmission of Middle East respirato...</td>\n",
       "      <td>The ongoing Middle East respiratory syndrome c...</td>\n",
       "      <td>2019 Nov 12</td>\n",
       "      <td>['Rodon, Jordi', 'Okba, Nisreen M. A.', 'Te, N...</td>\n",
       "      <td>5.183516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>Hendra Virus Vaccine, a One Health Approach to...</td>\n",
       "      <td>In recent years, the emergence of several high...</td>\n",
       "      <td>2014 Mar</td>\n",
       "      <td>['Middleton, Deborah', 'Pallister, Jackie', 'K...</td>\n",
       "      <td>5.183516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>Russian–United States vaccine science diplomac...</td>\n",
       "      <td>Russian–United States vaccine science diplomac...</td>\n",
       "      <td>2017 May 25</td>\n",
       "      <td>Hotez, Peter J.</td>\n",
       "      <td>5.158567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12605</th>\n",
       "      <td>Animal-to-Human SARS-associated Coronavirus Tr...</td>\n",
       "      <td>Animal-to-Human SARS-associated Coronavirus Tr...</td>\n",
       "      <td>2004 May</td>\n",
       "      <td>['Lun, Zhao-Rong', 'Qu, Liang-Hu']</td>\n",
       "      <td>5.099678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>EV71 vaccines: a milestone in the history of g...</td>\n",
       "      <td>EV71 vaccines: a milestone in the history of g...</td>\n",
       "      <td>2014 Apr 16</td>\n",
       "      <td>Lu, Shan</td>\n",
       "      <td>5.079551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11056</th>\n",
       "      <td>A Pneumonia Case Associated with Type 2 Polio ...</td>\n",
       "      <td>A Pneumonia Case Associated with Type 2 Polio ...</td>\n",
       "      <td>2017 Jan 5</td>\n",
       "      <td>['Li, Mao-Zhong', 'Zhang, Tie-Gang', 'Li, Ai-H...</td>\n",
       "      <td>5.079551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>SARS Transmission and Commercial Aircraft</td>\n",
       "      <td>SARS Transmission and Commercial Aircraft</td>\n",
       "      <td>2004 Aug</td>\n",
       "      <td>['Breugelmans, J. Gabrielle', 'Zucs, Phillip',...</td>\n",
       "      <td>4.935924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<__main__.SearchResults at 0x23892c41ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_papers.search('vaccine transmission')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cord",
   "language": "python",
   "name": "cord"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
